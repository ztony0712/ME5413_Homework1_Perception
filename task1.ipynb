{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ME5413: Autonomous Mobile Robot  \n",
    "\n",
    "### Homework 1: Perception  \n",
    "Due date: 22 February 2024 (Thurs) - 2359 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 Single-Object Tracking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1: (x, y, w, h) = (173, 294, 121, 190)\n",
      "Sequence 2: (x, y, w, h) = (240, 25, 110, 315)\n",
      "Sequence 3: (x, y, w, h) = (747, 243, 81, 204)\n",
      "Sequence 4: (x, y, w, h) = (465, 3, 269, 513)\n",
      "Sequence 5: (x, y, w, h) = (160, 463, 70, 168)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Run these blocks one by one to avoid errors\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Read the initial template area\n",
    "# x, y is the top-left corner of the template area\n",
    "# w, h is the width and height of the template area\n",
    "firsttrack_list = []\n",
    "frame_paths_list = []\n",
    "template_init_list = []\n",
    "prev_list = []\n",
    "for seq_number in range(1, 6):\n",
    "    with open(f'data/Task 1/seq_{seq_number}/firsttrack.txt', 'r') as file:\n",
    "        x, y, w, h = map(int, file.read().strip().split(','))\n",
    "    print(f'Sequence {seq_number}: (x, y, w, h) = ({x}, {y}, {w}, {h})')\n",
    "    firsttrack_list.append((x, y, w, h))\n",
    "    # path init\n",
    "    template_path = f'data/Task 1/seq_{seq_number}/img/001.jpg'\n",
    "    template_img = cv2.imread(template_path)\n",
    "    template_init = template_img[y:y+h, x:x+w]\n",
    "    template_init_list.append(template_init)\n",
    "\n",
    "    frame_paths = [f'data/Task 1/seq_{seq_number}/img/{i:03}.jpg' for i in range(1, 101)]\n",
    "    frame_paths_list.append(frame_paths)\n",
    "\n",
    "prev_list = firsttrack_list\n",
    "\n",
    "    \n",
    "def crop_result(frame, match_x, match_y, match_width, match_hight):\n",
    "    # Preprocess the matched region\n",
    "    matched_region = frame[match_y:match_y+match_hight,match_x:match_x+match_width]\n",
    "    matched_region_gray = cv2.cvtColor(matched_region, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(matched_region_gray, (7, 7), 0)\n",
    "    equalized = cv2.equalizeHist(blurred)\n",
    "    # Edge detection\n",
    "    edge_detected_image = cv2.Canny(equalized, 100, 200)\n",
    "    contours, _ = cv2.findContours(edge_detected_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If contours are found, update the size based on the largest contour\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x_b, y_b, w_b, h_b = cv2.boundingRect(largest_contour)\n",
    "        # Cropped region can't be smaller than 75% of the original area\n",
    "        original_area = match_hight * match_width\n",
    "        min_area_threshold = original_area * 0.75\n",
    "        if w_b * h_b < min_area_threshold:\n",
    "            return match_x, match_y, match_width, match_hight\n",
    "        x_c, y_c =match_x + x_b, match_y + y_b\n",
    "        w_c, h_c = w_b, h_b\n",
    "    else:\n",
    "        x_c, y_c = match_x, match_y\n",
    "        w_c, h_c = match_width, match_hight \n",
    "\n",
    "    return x_c, y_c, w_c, h_c\n",
    "\n",
    "# Calculate the direction vector\n",
    "def calculate_direction_vector(prev_prev, prev):\n",
    "    center_prev_prev = (prev_prev[0] + prev_prev[2] / 2, prev_prev[1] + prev_prev[3] / 2)\n",
    "    center_prev = (prev[0] + prev[2] / 2, prev[1] + prev[3] / 2)\n",
    "    direction_vector = (center_prev[0] - center_prev_prev[0], center_prev[1] - center_prev_prev[1])\n",
    "    return direction_vector\n",
    "\n",
    "# Timing-based dynamic template match\n",
    "def timing_base_dynamic_template_match(frame, template, prev, prev_prev, search_padding=10, direction_scale=0.8):\n",
    "    x_prev, y_prev, w_prev, h_prev = prev\n",
    "\n",
    "    # Calculate the direction vector and its module\n",
    "    direction_vector = calculate_direction_vector(prev_prev, prev)\n",
    "    module = np.linalg.norm(direction_vector)\n",
    "    # Generate the dynamic padding and direction scale\n",
    "    dynamic_padding = int(search_padding + module)\n",
    "    dynamic_direction_scale = direction_scale\n",
    "    if module < 10:\n",
    "        dynamic_direction_scale = 0.4\n",
    "    \n",
    "    # According to the direction vector, calculate the start point of the search window\n",
    "    search_x_start = max(0, int(x_prev + direction_vector[0]*dynamic_direction_scale))\n",
    "    search_y_start = max(0, int(y_prev + direction_vector[1]*dynamic_direction_scale))\n",
    "    \n",
    "    # Define the size of the search window\n",
    "    search_w = int(w_prev + dynamic_padding)\n",
    "    search_h = int(h_prev + dynamic_padding)\n",
    "    # Ensure the search window is within the frame\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    search_w = min(search_w, frame_width - search_x_start)\n",
    "    search_h = min(search_h, frame_height - search_y_start)\n",
    "    \n",
    "    # Adjust the start point of the search window\n",
    "    search_x = max(0, search_x_start + w_prev // 2 - search_w // 2)\n",
    "    search_y = max(0, search_y_start + h_prev // 2 - search_h // 2)\n",
    "    # Ensure the search window is within the frame\n",
    "    # Or return the previous result\n",
    "    search_region = frame[search_y:search_y + search_h, search_x:search_x + search_w]\n",
    "    if search_w < template.shape[1] or search_h < template.shape[0]:\n",
    "        return prev\n",
    "    \n",
    "    # Template match\n",
    "    result = cv2.matchTemplate(search_region, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    # Calculate the matched region\n",
    "    match_width, match_hight = int(template.shape[1]), int(template.shape[0])\n",
    "    match_x, match_y = max_loc[0] + search_x, max_loc[1] + search_y\n",
    "    # Crop the matched region based on the contours\n",
    "    x_c, y_c, w_c, h_c = crop_result(frame, match_x, match_y, match_width, match_hight)\n",
    "    x_d, y_d, w_d, h_d = x_c, y_c, w_c, h_c\n",
    "    return x_d, y_d, w_d, h_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Template Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime of seq_1 through dynamic method are 0.70 seconds\n",
      "The runtime of seq_2 through dynamic method are 0.28 seconds\n",
      "The runtime of seq_3 through dynamic method are 0.54 seconds\n",
      "The runtime of seq_4 through dynamic method are 0.43 seconds\n",
      "The runtime of seq_5 through dynamic method are 0.47 seconds\n"
     ]
    }
   ],
   "source": [
    "tm_lists = []\n",
    "kalman_array = []\n",
    "for seq_idx in range(5):\n",
    "    output_lines = []\n",
    "    tm_list = []\n",
    "    prev = prev_list[seq_idx]  # Initialize the previous result\n",
    "    prev_prev = prev  # Initialize the previous previous result\n",
    "\n",
    "    template = template_init_list[seq_idx]\n",
    "    start_time = time.time()\n",
    "    for frame_idx, path in enumerate(frame_paths_list[seq_idx]):\n",
    "        frame = cv2.imread(path)\n",
    "        if frame_idx == 0:\n",
    "            x_d, y_d, width, height = prev\n",
    "        else:\n",
    "            x_d, y_d, width, height = timing_base_dynamic_template_match(frame, template, prev, prev_prev)\n",
    "        tm_list.append((x_d, y_d, width, height))\n",
    "        output_lines.append(f'{x_d},{y_d},{width},{height}\\n')\n",
    "        # Update the previous and prev_prev\n",
    "        prev_prev = prev\n",
    "        prev = (x_d, y_d, width, height)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"The runtime of seq_{seq_idx+1} through dynamic method are {duration:.2f} seconds\")\n",
    "    # Write the result to the file\n",
    "    with open(f'data/Task 1/seq_{seq_idx+1}/trajectory.txt', 'w') as file:\n",
    "        file.writelines(output_lines)\n",
    "    tm_lists.append(tm_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Kalman Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_list = []\n",
    "for seq_number in range(1, 6):\n",
    "    ground_truth = []\n",
    "    with open(f'data/Task 1/seq_{seq_number}/groundtruth.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            ground_truth.append(list(map(int, line.strip().split(','))))\n",
    "    ground_truth_list.append(ground_truth)\n",
    "\n",
    "for seq_idx in range(5):\n",
    "    # Initialize Kalman filter\n",
    "    kalman = cv2.KalmanFilter(4, 2) # 4: state, 2: measurement\n",
    "    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32) # \n",
    "    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "    kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "    kalman.measurementNoiseCov = np.array([[1, 0], [0, 1]], np.float32) * 1\n",
    "    # Initialize the state\n",
    "    x_init, y_init, _, _ = firsttrack_list[seq_idx]\n",
    "    kalman.statePre = np.array([x_init, y_init, 0, 0], np.float32)\n",
    "    kalman.statePost = np.array([x_init, y_init, 0, 0], np.float32)\n",
    "    template = template_init_list[seq_idx]\n",
    "\n",
    "    \"\"\"\n",
    "        uncomment the following part to change kalman to original template match\n",
    "    \"\"\"\n",
    "    # output_lines = []\n",
    "    # start_time = time.time()\n",
    "    for i, path in enumerate(frame_paths_list[seq_idx]):\n",
    "        # 1. Predict step\n",
    "        prediction = kalman.predict()\n",
    "        # gt_x, gt_y, gt_w, gt_h = tm_lists[seq_idx][i]\n",
    "        gt_x, gt_y, gt_w, gt_h = ground_truth_list[seq_idx][i]\n",
    "        pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "\n",
    "        # 2. Correct and update step\n",
    "        measurement = np.array([gt_x, gt_y], np.float32)\n",
    "        corrected_state = kalman.correct(measurement)\n",
    "        final_pred_x, final_pred_y = int(corrected_state[0]), int(corrected_state[1])\n",
    "\n",
    "        \"\"\"\n",
    "            uncomment the following part to change kalman to original template match\n",
    "        \"\"\"\n",
    "        # frame = cv2.imread(path)\n",
    "        # result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "        # _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        # final_pred_x, final_pred_y = max_loc\n",
    "        # gt_w, gt_h = template.shape[1], template.shape[0]\n",
    "        # output_lines.append(f\"{final_pred_x},{final_pred_y},{gt_w},{gt_h}\\n\")\n",
    "    # end_time = time.time()\n",
    "    # duration = end_time - start_time\n",
    "    # print(f\"The runtime of seq_{seq_idx+1} through original method are {duration:.2f} seconds\")\n",
    "    # Write the result to the file\n",
    "    with open(f'data/Task 1/seq_{seq_idx+1}/kalman_trajectory.txt', 'w') as file:\n",
    "        file.writelines(output_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the Single object tracking algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_iou(frame, ground_truth):\n",
    "    x_r, y_r, w_r, h_r = frame\n",
    "    x_t, y_t, w_t, h_t = ground_truth\n",
    "    # Calculate the overlap area\n",
    "    top_left_overlap = (max(x_t, x_r), max(y_t, y_r))\n",
    "    bottom_right_overlap = (min(x_t + w_t, x_r + w_r), min(y_t + h_t, y_r + h_r))\n",
    "    overlap_w = max(0, bottom_right_overlap[0] - top_left_overlap[0])\n",
    "    overlap_h = max(0, bottom_right_overlap[1] - top_left_overlap[1])\n",
    "    overlap_area = overlap_w * overlap_h\n",
    "    union_area = w_t * h_t + w_r * h_r - overlap_area\n",
    "    # Calculate the IoU\n",
    "    iou = overlap_area / union_area if union_area > 0 else 0\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Calculate the TP, FP, FN\n",
    "def cal_results(iou, TP, FP, FN):\n",
    "    if iou == 0:\n",
    "        FN += 1\n",
    "    else:\n",
    "        if iou >= 0.5:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            FN += 1\n",
    "    return TP, FP, FN\n",
    "\n",
    "# Calculate the metrics of recall, precision, fscore, and average IoU\n",
    "def cal_metrics(TP, FP, FN, iou_list):\n",
    "    # recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    # fscore = 2 * recall * precision / (recall + precision) if (recall + precision) > 0 else 0\n",
    "    average_iou = sum(iou_list) / len(iou_list) if iou_list else 0\n",
    "    \n",
    "    return precision, average_iou\n",
    "\n",
    "# Draw the IoU curve and add the metrics\n",
    "def draw_plt(d_metrics, k_metrics, detect_iou_list, kalman_iou_list):\n",
    "    d_precision, d_average_iou = d_metrics\n",
    "    k_precision, k_average_iou = k_metrics\n",
    "\n",
    "    # Add the text labels\n",
    "    plt.plot(detect_iou_list, label='Dynamic IoU')\n",
    "    plt.plot(kalman_iou_list, label='Original IoU')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.title('IoU Over Frames')\n",
    "    # Add and adjust the text labels\n",
    "    plt.gcf().text(0.1, 0.95, f'Dynamic - Precision: {d_precision:.2f}, Avg IoU: {d_average_iou:.2f}', fontsize=9)\n",
    "    plt.gcf().text(0.1, 0.92, f'Original - Precision: {k_precision:.2f}, Avg IoU: {k_average_iou:.2f}', fontsize=9)\n",
    "    plt.gcf().subplots_adjust(top=0.85)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = 'data/Task 1/results'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # Define the output path\n",
    "    output_path = os.path.join(output_dir, f'seq_{seq_number}_plt.png')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "detect_list, kalman_list = [], []\n",
    "for seq_number in range(1, 6):\n",
    "    with open(f'data/Task 1/seq_{seq_number}/trajectory.txt', 'r') as file:\n",
    "        # Read the trajectory file and store the results in detect_list\n",
    "        detect_array = []\n",
    "        for line in file:\n",
    "            x_d, y_d, w_d, h_d = map(int, line.strip().split(','))\n",
    "            detect_array.append([x_d, y_d, w_d, h_d])\n",
    "        detect_list.append(detect_array)\n",
    "\n",
    "    with open(f'data/Task 1/seq_{seq_number}/kalman_trajectory.txt', 'r') as file:\n",
    "        # Read the trajectory file and store the results in kalman_list\n",
    "        kalman_array = []\n",
    "        for line in file:\n",
    "            x_d, y_d, w_d, h_d = map(int, line.strip().split(','))\n",
    "            kalman_array.append([x_d, y_d, w_d, h_d])\n",
    "        kalman_list.append(kalman_array)\n",
    "\n",
    "    with open(f'data/Task 1/seq_{seq_number}/groundtruth.txt', 'r') as file:\n",
    "        detect_iou_list, kalman_iou_list = [], []\n",
    "        d_FP, d_TP, d_FN = 0, 0, 0\n",
    "        k_FP, k_TP, k_FN = 0, 0, 0\n",
    "        for index, line in enumerate(file):\n",
    "            x_t, y_t, w_t, h_t = map(int, line.strip().split(','))\n",
    "            if index < len(detect_array) :\n",
    "                detect = detect_array[index]\n",
    "                kalman = kalman_array[index]\n",
    "                # Calculate the IoU\n",
    "                detect_iou = cal_iou(detect, [x_t, y_t, w_t, h_t])\n",
    "                kalman_iou = cal_iou(kalman, [x_t, y_t, w_t, h_t])\n",
    "                # Store the IoU in the iou list\n",
    "                detect_iou_list.append(detect_iou)\n",
    "                kalman_iou_list.append(kalman_iou)\n",
    "                # Calculate the TP, FP, FN\n",
    "                d_TP, d_FP, d_FN = cal_results(detect_iou, d_TP, d_FP, d_FN)\n",
    "                k_TP, k_FP, k_FN = cal_results(kalman_iou, k_TP, k_FP, k_FN)\n",
    "        # Calculate the metrics\n",
    "        d_metrics = cal_metrics(d_TP, d_FP, d_FN, detect_iou_list)\n",
    "        k_metrics = cal_metrics(k_TP, k_FP, k_FN, kalman_iou_list)\n",
    "        # Draw the IoU curve and add the metrics\n",
    "        draw_plt(d_metrics, k_metrics, detect_iou_list, kalman_iou_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Visualise the results as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_idx in range(5):\n",
    "    video = [] # Initialize the video list\n",
    "    frame_paths = frame_paths_list[seq_idx]\n",
    "    # Read the first frame to get the width and height\n",
    "    width, height = cv2.imread(frame_paths[0]).shape[1], cv2.imread(frame_paths[0]).shape[0]\n",
    "    for frame_idx, path in enumerate(frame_paths):\n",
    "        detect_frame = detect_list[seq_idx][frame_idx]\n",
    "        kalman_frame = kalman_list[seq_idx][frame_idx]\n",
    "        frame = cv2.imread(path)\n",
    "\n",
    "        # Extract the coordinates of the detected and kalman bounding boxes\n",
    "        detect_top_left = detect_frame[:2]\n",
    "        detect_width_height = detect_frame[2:4]\n",
    "        detect_bottom_right = (detect_top_left[0] + detect_width_height[0], detect_top_left[1] + detect_width_height[1])\n",
    "        kalman_top_left = kalman_frame[:2]\n",
    "        kalman_width_height = kalman_frame[2:4]\n",
    "        kalman_bottom_right = (kalman_top_left[0] + kalman_width_height[0], kalman_top_left[1] + kalman_width_height[1])\n",
    "\n",
    "        # Mark the matching area with a rectangular box of the detected and kalman bounding boxes\n",
    "        cv2.rectangle(frame, detect_top_left, detect_bottom_right, (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, kalman_top_left, kalman_bottom_right, (0, 0, 255), 2)\n",
    "        video.append(frame)\n",
    "\n",
    "    # visualization video save\n",
    "    output_dir = 'data/Task 1/results'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_path = os.path.join(output_dir, f'seq_{seq_idx+1}_video.mp4')\n",
    "    # Create a video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, 30, (width, height))\n",
    "\n",
    "    # Write the frames to the video\n",
    "    for frame in video:\n",
    "        video_writer.write(frame)\n",
    "    video_writer.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose Improvements to the work if possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixle-comparison based template matching algorithm is not robust to changes in scale, rotation, and illumination.\n",
    "CNN, RNN, R-CNN, YOLO, SSD, and other deep learning-based object detection and tracking algorithms should be used to improve the performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
